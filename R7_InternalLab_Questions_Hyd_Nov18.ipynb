{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MyfMmMnPJjvn"
   },
   "source": [
    "## Train a simple convnet on the Fashion MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zjcGOJhcJjvp"
   },
   "source": [
    "In this, we will see how to deal with image data and train a convnet for image classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jR0Pl2XjJjvq"
   },
   "source": [
    "### Load the  `fashion_mnist`  dataset\n",
    "\n",
    "** Use keras.datasets to load the dataset **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9822,
     "status": "ok",
     "timestamp": 1560074559216,
     "user": {
      "displayName": "chirriboyina goutham",
      "photoUrl": "https://lh3.googleusercontent.com/-nT9FpT4tFy8/AAAAAAAAAAI/AAAAAAAAAQc/vjlOeGFhHHc/s64/photo.jpg",
      "userId": "08704550966497889895"
     },
     "user_tz": -330
    },
    "id": "Qr75v_UYJjvs",
    "outputId": "cbbd0045-0e20-4b61-d937-c26178f7cfbf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 7us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 3s 0us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hTI42-0qJjvw"
   },
   "source": [
    "### Find no.of samples are there in training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1317,
     "status": "ok",
     "timestamp": 1560074574075,
     "user": {
      "displayName": "chirriboyina goutham",
      "photoUrl": "https://lh3.googleusercontent.com/-nT9FpT4tFy8/AAAAAAAAAAI/AAAAAAAAAQc/vjlOeGFhHHc/s64/photo.jpg",
      "userId": "08704550966497889895"
     },
     "user_tz": -330
    },
    "id": "g2sf67VoJjvx",
    "outputId": "7208fd52-72b0-44d0-d680-e5bba5ad04f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1280,
     "status": "ok",
     "timestamp": 1560074578276,
     "user": {
      "displayName": "chirriboyina goutham",
      "photoUrl": "https://lh3.googleusercontent.com/-nT9FpT4tFy8/AAAAAAAAAAI/AAAAAAAAAQc/vjlOeGFhHHc/s64/photo.jpg",
      "userId": "08704550966497889895"
     },
     "user_tz": -330
    },
    "id": "zewyDcBlJjv1",
    "outputId": "3923015a-2730-4435-990b-a6566d498071"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WytT2eRnJjv4"
   },
   "source": [
    "### Find dimensions of an image in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1293,
     "status": "ok",
     "timestamp": 1560074584420,
     "user": {
      "displayName": "chirriboyina goutham",
      "photoUrl": "https://lh3.googleusercontent.com/-nT9FpT4tFy8/AAAAAAAAAAI/AAAAAAAAAQc/vjlOeGFhHHc/s64/photo.jpg",
      "userId": "08704550966497889895"
     },
     "user_tz": -330
    },
    "id": "XycQGBSGJjv5",
    "outputId": "3f2aab6d-6bfc-440b-9525-90b9cf1f832d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1300,
     "status": "ok",
     "timestamp": 1560074587391,
     "user": {
      "displayName": "chirriboyina goutham",
      "photoUrl": "https://lh3.googleusercontent.com/-nT9FpT4tFy8/AAAAAAAAAAI/AAAAAAAAAQc/vjlOeGFhHHc/s64/photo.jpg",
      "userId": "08704550966497889895"
     },
     "user_tz": -330
    },
    "id": "b4Zeb-p9cxiV",
    "outputId": "01358462-16ad-4427-fec4-88e3e3add8ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5jtdZ7RqJjv8"
   },
   "source": [
    "### Convert train and test labels to one hot vectors\n",
    "\n",
    "** check `keras.utils.to_categorical()` **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cKLxtz2EcxiZ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sAD3q5I6Jjv9"
   },
   "outputs": [],
   "source": [
    "y_test=tf.keras.utils.to_categorical(y_test,num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mgHSCXy3JjwA"
   },
   "outputs": [],
   "source": [
    "y_train=tf.keras.utils.to_categorical(y_train,num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xO5BRBzBJjwD"
   },
   "source": [
    "### Normalize both the train and test image data from 0-255 to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3fUQpMHxJjwE"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Okwo_SB5JjwI"
   },
   "outputs": [],
   "source": [
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "da5-DwgrJjwM"
   },
   "source": [
    "### Reshape the data from 28x28 to 28x28x1 to match input dimensions in Conv2D layer in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1309,
     "status": "ok",
     "timestamp": 1560074611967,
     "user": {
      "displayName": "chirriboyina goutham",
      "photoUrl": "https://lh3.googleusercontent.com/-nT9FpT4tFy8/AAAAAAAAAAI/AAAAAAAAAQc/vjlOeGFhHHc/s64/photo.jpg",
      "userId": "08704550966497889895"
     },
     "user_tz": -330
    },
    "id": "LPGVQ-JJJjwN",
    "outputId": "cdb2a3eb-6051-4286-ddb6-cc951f3a8e5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OFRRTJq8JjwQ"
   },
   "source": [
    "### Import the necessary layers from keras to build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dWTZYnKSJjwR"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C18AoS7eJjwU"
   },
   "source": [
    "### Build a model \n",
    "\n",
    "** with 2 Conv layers having `32 3*3 filters` in both convolutions with `relu activations` and `flatten` before passing the feature map into 2 fully connected layers (or Dense Layers) having 128 and 10 neurons with `relu` and `softmax` activations respectively. Now, using `categorical_crossentropy` loss with `adam` optimizer train the model with early stopping `patience=5` and no.of `epochs=10`. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1755827,
     "status": "ok",
     "timestamp": 1560074386108,
     "user": {
      "displayName": "chirriboyina goutham",
      "photoUrl": "https://lh3.googleusercontent.com/-nT9FpT4tFy8/AAAAAAAAAAI/AAAAAAAAAQc/vjlOeGFhHHc/s64/photo.jpg",
      "userId": "08704550966497889895"
     },
     "user_tz": -330
    },
    "id": "DORCLgSwJjwV",
    "outputId": "f531103b-b244-41e4-9a49-97d2915a24fe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1...)`\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(33, (3, 3))`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 196s 3ms/step - loss: 0.3733 - acc: 0.8642 - val_loss: 0.2841 - val_acc: 0.8968\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 194s 3ms/step - loss: 0.2351 - acc: 0.9137 - val_loss: 0.2502 - val_acc: 0.9079\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 195s 3ms/step - loss: 0.1735 - acc: 0.9359 - val_loss: 0.2505 - val_acc: 0.9136\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 196s 3ms/step - loss: 0.1245 - acc: 0.9535 - val_loss: 0.2724 - val_acc: 0.9151\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 195s 3ms/step - loss: 0.0880 - acc: 0.9674 - val_loss: 0.2910 - val_acc: 0.9111\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 195s 3ms/step - loss: 0.0609 - acc: 0.9773 - val_loss: 0.3673 - val_acc: 0.9049\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 195s 3ms/step - loss: 0.0415 - acc: 0.9844 - val_loss: 0.3799 - val_acc: 0.9110\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 194s 3ms/step - loss: 0.0317 - acc: 0.9887 - val_loss: 0.4296 - val_acc: 0.9121\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 194s 3ms/step - loss: 0.0236 - acc: 0.9917 - val_loss: 0.4911 - val_acc: 0.9134\n",
      "Epoch 00009: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0fa8076710>"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Define model\n",
    "    model = Sequential()\n",
    "\n",
    "    # 1st Conv Layer\n",
    "    model.add(keras.layers.Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "\n",
    "    # 2nd Conv Layer\n",
    "    model.add(keras.layers.Convolution2D(33, 3, 3))\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "\n",
    "    # Fully Connected Layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "\n",
    "    # Prediction Layer\n",
    "    model.add(Dense(10))\n",
    "    model.add(keras.layers.Activation('softmax'))\n",
    "\n",
    "    # Loss and Optimizer\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    # Store Training Results\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='auto')\n",
    "    callback_list = [early_stopping]\n",
    "\n",
    "    # Train the model2\n",
    "    model.fit(x_train, y_train, batch_size=32, nb_epoch=10, \n",
    "              validation_data=(x_test, y_test), callbacks=callback_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ju69vKdIJjwX"
   },
   "source": [
    "### Now, to the above model add `max` pooling layer of `filter size 2x2` and `dropout` layer with `p=0.25` after the 2 conv layers and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 670
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 94906,
     "status": "ok",
     "timestamp": 1560074910760,
     "user": {
      "displayName": "chirriboyina goutham",
      "photoUrl": "https://lh3.googleusercontent.com/-nT9FpT4tFy8/AAAAAAAAAAI/AAAAAAAAAQc/vjlOeGFhHHc/s64/photo.jpg",
      "userId": "08704550966497889895"
     },
     "user_tz": -330
    },
    "id": "L2hAP94vJjwY",
    "outputId": "78e62b99-840c-4131-888d-67c0c024872c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1...)`\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(33, (3, 3))`\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 15s 243us/step - loss: 0.3968 - acc: 0.8574 - val_loss: 0.3326 - val_acc: 0.8762\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.2614 - acc: 0.9040 - val_loss: 0.2631 - val_acc: 0.9025\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.2138 - acc: 0.9210 - val_loss: 0.2459 - val_acc: 0.9097\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.1799 - acc: 0.9338 - val_loss: 0.2230 - val_acc: 0.9191\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.1497 - acc: 0.9439 - val_loss: 0.2231 - val_acc: 0.9206\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.1302 - acc: 0.9508 - val_loss: 0.2486 - val_acc: 0.9166\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.1098 - acc: 0.9590 - val_loss: 0.2347 - val_acc: 0.9230\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: 0.0933 - acc: 0.9650 - val_loss: 0.2524 - val_acc: 0.9232\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: 0.0831 - acc: 0.9684 - val_loss: 0.2489 - val_acc: 0.9234\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.0709 - acc: 0.9734 - val_loss: 0.3086 - val_acc: 0.9208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa433b9a400>"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define model\n",
    "    model1 = Sequential()\n",
    "\n",
    "\n",
    "    # 1st Conv Layer\n",
    "    model1.add(keras.layers.Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n",
    "    model1.add(keras.layers.Activation('relu'))\n",
    "\n",
    "    # 2nd Conv Layer\n",
    "    model1.add(keras.layers.Convolution2D(33, 3, 3))\n",
    "    model1.add(keras.layers.Activation('relu'))\n",
    "    \n",
    "    #Max pooling layer\n",
    "    model1.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    #Dropout layer\n",
    "    model1.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "    # Fully Connected Layer\n",
    "    model1.add(Flatten())\n",
    "    model1.add(Dense(128))\n",
    "    model1.add(keras.layers.Activation('relu'))\n",
    "\n",
    "    # Prediction Layer\n",
    "    model1.add(Dense(10))\n",
    "    model1.add(keras.layers.Activation('softmax'))\n",
    "\n",
    "    # Loss and Optimizer\n",
    "    model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    # Store Training Results\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='auto')\n",
    "    callback_list = [early_stopping]\n",
    "\n",
    "    # Train the model2\n",
    "    model1.fit(x_train, y_train, batch_size=32, nb_epoch=10, \n",
    "              validation_data=(x_test, y_test), callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lGTA3bfEJjwa"
   },
   "source": [
    "### Now, to the above model, lets add Data Augmentation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F6gX8n5SJjwb"
   },
   "source": [
    "### Import the ImageDataGenrator from keras and fit the training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cbz4uHBuJjwc"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# This will do preprocessing and realtime data augmentation:\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=50,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=False,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "\n",
    "# Prepare the generator\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pl-8dOo7Jjwf"
   },
   "source": [
    "#### Showing 5 versions of the first image in training dataset using image datagenerator.flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1286,
     "status": "ok",
     "timestamp": 1560075376714,
     "user": {
      "displayName": "chirriboyina goutham",
      "photoUrl": "https://lh3.googleusercontent.com/-nT9FpT4tFy8/AAAAAAAAAAI/AAAAAAAAAQc/vjlOeGFhHHc/s64/photo.jpg",
      "userId": "08704550966497889895"
     },
     "user_tz": -330
    },
    "id": "DpI1_McYJjwg",
    "outputId": "ce7a9972-0b33-4ed1-a7d1-a29afa7c8029",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAABcCAYAAABz9T77AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGExJREFUeJztnXeMXcUVhz8HCDWhBnAIvRoIYEro\nNSAQnQQQNYReRBEhVJFCSRDFEsGig2h/AAKMQ6KAEYgiOthyYnpvprcAoYPzR/h2Zs/bZ6/t3bd7\nw/n+eXq77827M3fuvb9z5pwzQyZNmkSSJEnSXL430AeQJEmSTB95I0+SJGk4eSNPkiRpOHkjT5Ik\naTh5I0+SJGk4eSNPkiRpOHkjT5IkaTh5I0+SJGk4eSNPkiRpODN28seGDBnynUgjnTRp0pDefjbH\npJXBOCZDhvzv8GeYYQYAvve9/2mg2Wefvesziy++OABfffUVAI899hgAX3/9dY9tTs2YfHsMg25c\nHAczxB2fH/zgB12fWWaZZQB4++23AXj++ed7bOtHP/oRAG+99daAzBXPcbts97nmmguAHXbYAYBl\nl10WgHXXXReABRZYAIAxY8YAMGLECADmm28+AL7//e93tfXqq68C8PLLL/fq2KY0V1KRJ0mSNJyO\nKvIkaQoqTVXazDPPDBR1OeOMM3Z7BXjnnXcAePbZZyfb9hJLLNG3BzuAOD6+aqEsueSSXZ959913\ngfZKfN555wWKRTNQREXu+5VXXhkox/ezn/0MgA8++AAoSnvppZcGinJfZZVVABg5ciQA48aN6/qt\n3irx3pKKPEmSpOGkIk+SHlCVffPNNwCsvfbaAKy66qpAUVvXX39913ceeOCBHttSsanE55xzzn44\n4s6gStUS0f/7wx/+ECiK/OOPP+76TjsLReWq0tUK6jRaW57zFVdcEYBFF10UgJ/+9KdAq3W2+uqr\nA+W8apF9+umnALz//vsAbLzxxkD7+dEXpCJPkiRpOKnIk+80qkCVt6i6ZpttNgAWW2yxbp+fZ555\nADj22GO7vvPwww8DJSLByA39xbb52Wef9W0nOkBUy3PPPTcAu+yyC1CU+YcffgjA6aef3rYt1ftS\nSy0FFHX/+uuv9+ER94z++DoyxXOr1aXCHjp0KAATJ04EYPjw4QAsvPDC3doyKsk5NP/88wPFEtPi\n2Gyzzbp+c/z48QCMHTt2ssfrnJkSqciTJEkaTiry5DuJSvuTTz4BikpUTQ0bNgwoqmullVYCSqTC\nggsu2O17AKeeeioAJ5xwAgA//vGPgaI49ZlOKaplMKKCVZmrYkU1euihhwKlrwAXXXQRAHPMMQdQ\nojsclzfeeAOAl156qT8OHSj+bS2JbbbZput/M800E1B84p4fI5TWWWcdoChrlbZzx++LPnLXU/z8\nWmut1fUZlfjNN98MwFlnndWtDePxtXSmRCryJEmShpOKPOlCFaDK/PLLL4HuEQhNI/q47YuqcLnl\nlgNglllmAUq23gsvvAAUha56NItPpWTkBRQf6ymnnALAxRdfDBTF+eKLL/ZZv/qLmKnpq6pTv7bj\np79YtT3rrLMCcPDBB3e1acbj3/72t25tGeXRiXGxH6puI04AFlpoIaDMfxW4PnKP17FxDsV1lbiO\n4PWjD72OVtpggw2AotKNVd9zzz2BkuXqMUyJVORJkiQNJxX5t7SLXvh/RH+hGPurOtUXaCbeU089\nBRTfH7Qqtnb1KQYaz+v6668PFOWokrYuiv5s3xsnrlKyf3VtFSg+cyjjpbLTj96f8cN9jceuL9m5\nsskmmwCtsd/OiTXXXLNbOyp3KJEtWnqXXHIJ0Nm1Ai0qs0zra8C4cftipIhWmmPy1ltvAcXn7ZxQ\neft3Fbz3Etutr5EYubTtttsCcOuttwIl6qeuWTM5UpEnSZI0nO+8Io81NXz66lsF+Pzzz4HWJ3BT\nidaHSnz33XcHihp75JFHgKJWJ0yY0NWGEQZRicfaGwOl1O2jkQf6JPU9eg59jZUL9YHbjp/74osv\nuv1d1QatkRy26d8Hk49c1eg895wbraO/X593VJmqWOPp9YOrPo3ogBKhoTWjpaKl1584D/VTawU8\n9NBDXZ8xc9N57jn1nP/73/8G4JVXXgFa1wucExLvF865ui6PMfOOr/NpjTXWAOD8888HYNSoUb3q\nZyryJEmShpM38iRJkobT6Y0lgPbmdvy/bo52hfn74rdjcaRNN90U6F5q9KOPPgLKYsddd90FFDO8\nadhX+24IlAta9svxN9RsvfXW62rjuuuuA+Cf//wnUMzQOL61Odnf1AtY9tG+aOrrEjCETDPZhSr7\nLP/5z3+6taPZHV0uUFwH/oZJRM6lK664Aiguq4FE19HWW28NlP7pZnPOG64nLv7GxdDobnRRGcq8\niYt+umUMS+yP68nfch56Pq+99tquz2y44YZA6avHGd1p9sn7kXPKtuPCvy4ZP1/PLduO5ZBjuOf2\n22/fq36mIk+SJGk4HVXkJls8/fTTQFF6hvv861//6vZ5n071FkntlN+UiJ/3N1VPJnr4dK6L3Bs+\ndsMNNwDND1F0LJZffnmgKHEXe1Qanq/77rsPKMkxAL/97W8BePDBB4FSMOqZZ54BygKPCSOdRvXj\nnHruueeAkjpuGJ3zwHPqq4tRJnH4d9VZLKoFpWBUTKz65S9/CRRlutNOO/VJH6cHFye1GhZZZBGg\nddHfxU/njItzUZVqqagsXfCr23I8TBbSEtxuu+0AOPLII/uqey1EtV8f33vvvQeUuaHydiy8/zin\nxTHUenFueI9y8wjHuP7N6HUQC3RpFcRQ4XakIk+SJGk4HVXkql43L60L10ApIHPmmWcCPYf76Zuc\nkt98Sv740047DSipuqbp+tS1FCmUoHxViyFtWhaDNSmm3dZVvldVq4xUU/p67a9jY+lNKKGIqizT\nmg1bs61Olmytxz/22RC43XbbDSgKUpWkYjNt3PUQ24klS223ts5UbjG0UdVuuJpFpAYCrx/Pi5aF\nIXiOg33x//psVZ0qxrgWIXUii+sRjp1jrD/eMr9eV51AFQ5w0kknAeVcb7TRRkCxxjxux8AxsV9a\nJX7f9QMtsJ5CdbVs9NlrDajI/c3ebn+XijxJkqThdFSR+6T6zW9+AxSfok8+/amWf1SZ+5SC9qUu\nY8GamAigL+qwww4DyvZLJmv4eZ+udXs+ifV16RN78sknu312sCnydhE6+gBXWGEFoCjGqDx8VW25\n6SwUBacqUfFaIEqlVheV6iRxHcM+xCgLFWaMStHS8O+OjWM4uQgL1xpUW85zlZxrE52i9rN6/F5T\njz/+OFDOrRZp3P7McTKJx4gTXx3PnqJ5VPeq+KhG/U6d1t9J9GVbgvcvf/kLUNYyPH5foxXie+eM\n15flALxPeF+r8V6ihWBb3is9P9572pGKPEmSpOF0VJH/4he/AIo/SJXjk9knnn7r8847D+ge82kE\nyR133AEUf65tRGzLokmHHHIIUJSEClwFolqoFZ0xt6+99hpQVLxPYBVXU9Dfq+L2POg3jdaN56X+\nuyre/+kPVIWoyGLa+kDhfLnqqquA4is38sDjVZF7zrUWVbX61J0fdSq6BbQcm9oPW7fR6U2Ga8vM\ntQstqdGjRwPw85//HChlU50TKnGVo99/8803gXK9+PfJWSq27RjaZozNHyg8LssQx40lHDPnSowo\niXHyeg+819QbUHi/MtZcFR+jqGL6fztSkSdJkjScjipyn2QqFdW0TzLf+zn9RL/+9a+72tC37d9u\nv/12oPi57rzzTqDEhxshc/TRRwNFMcaVZp98+tLr2HWVhLHFqjhLnd59991A72M+O0UsYCWqZJVC\n9PWpTIwu8H0dEx7XHlRkRrr4vi4qNRg444wzgKK2zOSNVoeqOq6dOFYq0bqMresBjlec19IXmcrT\nSlTMWmFek1EBeqyexzhnjE7xfU/x0frjbTtGwMTsxoFGS+GPf/wjAMcffzxQrHvPr8cfcwscKyO7\njMWvN1JWiTs3HBOte+eV64S/+tWvJnvMqciTJEkaTkcfgaqdqHp9wumD0i+pWqgzoqyHYNSEBe31\nu6vMzdD0SVf7MqE1okP1qcJQeUDxl/pqCUzjYFUcZg8OFqIi/8lPfgLAVlttBRRfebut3FRjnidV\nKBQfX60yoDXz1s/52wONY+Fmt/qG9VFqlcR1A+dgVF11JI8RBsagq7ZinoE5CgOV9VpjlNHll18O\nlGMyflmV7Hg4Tvbf68vzHuv0QBlzv6vqjCWkBypjOmazenz3338/0FpHxjHxeI308b519dVXA2XM\nnCN1xJ3XRbRcvY+dffbZADz66KO96kMq8iRJkobTUUWuH04fc1z51m/ke1Vx7TvTx60fS4WkUjdL\nTCUVq5/F+Fh9UR6b7+vf9Gmp3z36GfW31qvSfUW7SIdavbTb3EFUBn5HpRgtI4/fvte1Vep26s/Y\nZhxflZ61VwZakbdbvzDL8rjjjgOKGmu3sa79cwyfeOKJrs+4aYHzRLQGVWTO4cGEUT369c8991yg\nzIEYSy0qS/votWtEF5S4euvyqFxty+9qyXR6rnj9xLULfd9mcLvpg5+z8qfH7f3M6LajjjoKKCq7\n9ixEK8XvuqGEa3+9JRV5kiRJw+moIr/gggsAOPnkk4FWv5pqR8USt0yCVgUoqvmYkSfRH6cvXDWg\nOtBHWPvF4sq9PjGjFLbcckugbL47PUTlGP2rPUWiREXerh7NzjvvDMDmm28OtMa9+j3VpmrBz9WK\nItbi8Lw4bv62amWw4Lwx286IowMOOABo7Yev0Xfu/KqzjlWvWjauPTgGsY7JYMT1n9///vcAXHnl\nlUCZb6rUmOkaq0HWVSGtv+61Zu2eGMXWLhek09gntwc0q9Lrw+vAzGi9A9ZqN8LEMdA7UK/TeY29\n/fbbAFxzzTVA8a9PLanIkyRJGk5HFbmK1Sev/rToX/MJpqKp/ZV+RrVorPmYMWOA4l8zIiP6yGPN\nDf31USX1VDfFJ7Fx2PpTx40b1+2Ypod29VriZrm14onRQI6B2ayumlvjI2bD2rbtxFrIsf2ecFxV\nbMaT6xcdaNr5Qe+9916gte6PfdZy0+JzvrhLlGsAUCwe56vzV0vOv8dIn8FAjBzRn29lQP29sZZK\nzAD173XVSxW3Y2kbKlm/0xfXz/QQY+D17avIo/Vuf8xFiJ6FGKNfXz+2ddtttwGlvsu0koo8SZKk\n4XRUkVs5zWylSy+9FCirvEaMLLjggkDPGXCqR592qsrHHnsMaK0b7VPS78VaGTHuOcaUQlFUscaC\nT2p9ZbUPeVpxVx4rr+mHj4q3tiA8VmPrfY3VC6N/PVb+02qJ6iwq9vo327Wh6lfhDhY8z6oplWas\nsWOst9E3joHRBK7j7LPPPl1tq8TMZXAO1tZT3eZgxPNn/LLvVeZGYMT1La9Hr786mkerbL/99gNa\n174c+/6I+uoNsU6/52vHHXcESt9i5nOML4/Wf1xPqPvnzlWuF04vqciTJEkazoAUN7jllluAsnef\nWXaqJGuaGAVQq+Pof/IpqapXSekXVv34lI07w/h9n8o+NesaIXGFXlSd+rv0m/Z2V4/69/yNE088\nESgV1+JeiCqgWh3H7MO4i0uswW3MqvHvqix/w/j9uDuMcbP1cQwfPrzbcWohOa5mvw4WHAstH2tE\nx5rZRi95Tj3X+nWNVKpVlhZl3BnI31TFG6GwxRZb9GHPpg/ndoyfd1co9221vlBcT3H+anUb7QJw\nxBFHAGU+GanhvHWcosLtT3rKPHVOu0OQc8Lj9HMer9eNc985EjPVnSP1/eN3v/tdt89OL6nIkyRJ\nGs6AKHKf3j7l3ZnjhBNOAIqK8+le7zKjaoz1e/faay+g1JvW72bkRlxpVj2pkvx7rOYHReFaa8VI\nhaim//znPwOw66679nos9t57726/YYy3x2fbHo9KqFZOKoJYMzv6g7VwrKuhAtGn7vf8TcfW315i\niSVaflNFZtSHn3UcB7oeebt9Sz1Hq622GtBa/8O+GxPcbteknqIz4o5L/n3EiBFAsUg9D4OZPfbY\nAyjROvZJNXrPPfcA5Try/UEHHdTVhhaeCtU54zg5ltYq6mknnb6ip0xpLQGzwjfZZBOgWJv22THQ\nKtML4Fy3HfvpteDOR7YL7Xc6m1ZSkSdJkjScAS0ArK/WWF79RvrUfIJZwwJa9z80k1PlZ80M4zP1\ncaqml156aaA8RfXHx1ohqoaejlfVoY/573//O1Ce0FODPnz9a/ZP5eBx+Kq6rqNWVMdG+7hOEKvw\n6ct3Nf7iiy8GSuVHY/L9vEpJn6ax4VDGM/rsPT7VSSdjputs13ZV+7R4jDTS8mmXmRojp4zCcS1A\ndQatdbadt9ZA1988mIkV/VxL0JrTAtFK3nPPPYEybkZbORehjKHz0rnrd1555RWgZJPaRn8Q/eHQ\nWsly9913B0pfY2XMOLeda16jnn+j2lz3MrKuP0hFniRJ0nDyRp4kSdJwhrRLCe+XHxsyZLI/pknv\nooILJi4IQjHPYtigpr4LKLoJYmF2F54se6uJqPmkyeViDhTTS7fBn/70J6Asxr744otAWVB74IEH\ner3n2/DhwydBCXdzwVQzLYYAxi3W6uNysVIXkOPpwq/ftc8WM/L4HUNNRYsbuchZuy40H2PYpsfl\nq+bp0KFDez0mU5on7agXqJ0fnjvD5lxY971jEououWDVbgzjwh0Ul8HDDz8MlGQP3XeRSZMmTdXe\ngNM6LtOCBaAs4hTLadjXuJmz41271HRfOT/j9nmHH344UFxPUzMufTEmBlfcdNNNQPcSvFD6qjvN\ne4NzTLei9xYX0K+//nqgbOY8PUX1pjQmqciTJEkazuDY7fRbfOKpEE0LttQolOIyFjFS+alCVeQu\n4LlxskrKUCgVpWpBRaGSV6HVbY4ePRooi5tjx44FSpGqejGwt6hC/H3fW8TexTTVTE8JBI6bY6F6\nituSqRx8XW+99YCiINolTak6eyrtK7Gcrbh463noT+oFLPuoleECulsD2jfngyrM7drihtSOgRaG\nr7YP8I9//AOAI488su861c/EcEpT7C0EVS/mQhkPr7+ozOP2jVCutVh8zXDjTi4Cewx1wp/3Ga3y\nWEo6btgeAy68hxjG6zzwXmXJhv4kFXmSJEnDGVSKXHzqqzRVwFD8TH/4wx+AEmyvgo6bJagMou+u\n3aaxKpBakftEthCQSlz029fJIVPLCy+8AJRNV01wMlXf/qhuah+5/7NPKvJYcjSm+ccUYn1//oav\nogqr2xDbdtz0w6tW+pOekqT066uKDAWLYZziObYt++PY2Hf/7nZuJvlA3xVA6gTOH8dMJa2qNJHO\ncMtY9tmElhiiF8Nl69/wu1pHhvF2Eo/FErVQrhfPrYo7lgyIJXp9NfTZ8MJzzjkHKJuXxGulP0hF\nniRJ0nAGpSKfHPow999/f6AkAJk8pM9StelTVLWpEtMXqJKIJSjrFF797SNHjpzssfm5qSGqyQkT\nJgDlqe6mFRZYMgmp9lH7xFdJqIKjulSFxTTlWN42RjJ5bHXhf8c3RiSoxPxOJxS5v1Vv2uv4mdBi\nn4xCiWWQfY2lVU2q0sKwPZNXLAnRFOI59tX+uTmGafJxLSHOmVgiWT9yrUKHDRsGwDHHHAOUtaaB\npN6C0LkQi+PZB987511P0YpxTc/tArXupsdCn1pSkSdJkjScxilyUX268q3fTUWh4lZpqRhMN/fp\na/x2rcCh+0ap++67L9A/GwnHKI+Y3m00jmnM6667LlBUDpRiP6ZF64tUVdqmY+Y6QEwpllg4zPd1\nJIJ/U6lFX6vvjeM3Nb4/qeN/o2UVLTTVVix0FNcLnB/6irUAb7zxRmDayjIMJFGJi2py2223Bcp1\nE3MUHC/njJFOXi++GocOxZL961//2pddmS5qH76x8lprrq94vTivtEi9Nl2vu/DCC4G+L4Q1NaQi\nT5IkaTiDKrOzL1CRH3jggUBRZvYzFqnSr6qaNbpFfx7AZZddBvR+9bkTmWl1aV+P3b76v5ht6Rio\nmv2ciiO+ut4QY62hKG5ftRwmTpwIFOvFyITx48f3+5jUVtWoUaOAEl2iotRv6Xk26zIqdaOh9PGf\ndtppADz00ENA32zXNhCZnXFNxqzpY489FmiN5mm3/hKvKy0afeu1H1xF7vZmU7rn9Of1Y/8322yz\nrr9ZEMw1LmPojWxxLj/99NMAXHHFFd3acmz6k8zsTJIk+T+no4o8SZIk6XtSkSdJkjScvJEnSZI0\nnLyRJ0mSNJy8kSdJkjScvJEnSZI0nLyRJ0mSNJy8kSdJkjScvJEnSZI0nLyRJ0mSNJy8kSdJkjSc\nvJEnSZI0nLyRJ0mSNJy8kSdJkjScvJEnSZI0nLyRJ0mSNJy8kSdJkjScvJEnSZI0nLyRJ0mSNJy8\nkSdJkjScvJEnSZI0nLyRJ0mSNJy8kSdJkjScvJEnSZI0nP8CKmZtHhhRYqwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "gen = datagen.flow(x_train[0:1], batch_size=1)\n",
    "for i in range(1, 6):\n",
    "    plt.subplot(1,5,i)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
    "    plt.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dmPl5yE8Jjwm"
   },
   "source": [
    "### Run the above model using fit_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 512
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 190372,
     "status": "ok",
     "timestamp": 1560075784048,
     "user": {
      "displayName": "chirriboyina goutham",
      "photoUrl": "https://lh3.googleusercontent.com/-nT9FpT4tFy8/AAAAAAAAAAI/AAAAAAAAAQc/vjlOeGFhHHc/s64/photo.jpg",
      "userId": "08704550966497889895"
     },
     "user_tz": -330
    },
    "id": "44ZnDdJYJjwn",
    "outputId": "a41b63b3-4059-4d85-858a-e91c203ee85f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1...)`\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(33, (3, 3))`\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., callbacks=[<keras.ca..., steps_per_epoch=1875, epochs=10)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.7793 - acc: 0.7119 - val_loss: 0.5460 - val_acc: 0.7980\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.5744 - acc: 0.7843 - val_loss: 0.4704 - val_acc: 0.8271\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.5094 - acc: 0.8090 - val_loss: 0.4354 - val_acc: 0.8437\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.4777 - acc: 0.8209 - val_loss: 0.4335 - val_acc: 0.8383\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.4517 - acc: 0.8312 - val_loss: 0.4190 - val_acc: 0.8466\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.4321 - acc: 0.8386 - val_loss: 0.4249 - val_acc: 0.8440\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.4183 - acc: 0.8434 - val_loss: 0.4029 - val_acc: 0.8522\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.4061 - acc: 0.8484 - val_loss: 0.3631 - val_acc: 0.8666\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3954 - acc: 0.8540 - val_loss: 0.3507 - val_acc: 0.8709\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3903 - acc: 0.8546 - val_loss: 0.3640 - val_acc: 0.8666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa426492c50>"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define model\n",
    "    model2 = Sequential()\n",
    "\n",
    "\n",
    "    # 1st Conv Layer\n",
    "    model2.add(keras.layers.Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n",
    "    model2.add(keras.layers.Activation('relu'))\n",
    "\n",
    "    # 2nd Conv Layer\n",
    "    model2.add(keras.layers.Convolution2D(33, 3, 3))\n",
    "    model2.add(keras.layers.Activation('relu'))\n",
    "    \n",
    "    #Max pooling layer\n",
    "    model2.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    #Dropout layer\n",
    "    model2.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "    # Fully Connected Layer\n",
    "    model2.add(Flatten())\n",
    "    model2.add(Dense(128))\n",
    "    model2.add(keras.layers.Activation('relu'))\n",
    "\n",
    "    # Prediction Layer\n",
    "    model2.add(Dense(10))\n",
    "    model2.add(keras.layers.Activation('softmax'))\n",
    "\n",
    "    # Loss and Optimizer\n",
    "    model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    # Store Training Results\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='auto')\n",
    "    callback_list = [early_stopping]\n",
    "\n",
    "    # Train the model2\n",
    "    model2.fit_generator(datagen.flow(x_train, y_train, batch_size=32),samples_per_epoch=x_train.shape[0], nb_epoch=10, \n",
    "              validation_data=(x_test, y_test), callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MwQQW5iOJjwq"
   },
   "source": [
    "###  Report the final train and validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1770,
     "status": "ok",
     "timestamp": 1560076043827,
     "user": {
      "displayName": "chirriboyina goutham",
      "photoUrl": "https://lh3.googleusercontent.com/-nT9FpT4tFy8/AAAAAAAAAAI/AAAAAAAAAQc/vjlOeGFhHHc/s64/photo.jpg",
      "userId": "08704550966497889895"
     },
     "user_tz": -330
    },
    "id": "c1SrtBEPJjwq",
    "outputId": "39431964-8f94-47f6-91f4-8ec0b675eb82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 53us/step\n",
      "[0.36401661043167116, 0.8666]\n"
     ]
    }
   ],
   "source": [
    "print(model2.evaluate(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4480,
     "status": "ok",
     "timestamp": 1560076080350,
     "user": {
      "displayName": "chirriboyina goutham",
      "photoUrl": "https://lh3.googleusercontent.com/-nT9FpT4tFy8/AAAAAAAAAAI/AAAAAAAAAQc/vjlOeGFhHHc/s64/photo.jpg",
      "userId": "08704550966497889895"
     },
     "user_tz": -330
    },
    "id": "ZBwVWNQC2qZD",
    "outputId": "d64d0f3b-5e6e-44ed-b44d-040c784c282b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 3s 54us/step\n",
      "[0.3376097192466259, 0.8740666666666667]\n"
     ]
    }
   ],
   "source": [
    "print(model2.evaluate(x_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p--D7KD3x8MI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "R7_InternalLab_Questions_Hyd_Nov18.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
