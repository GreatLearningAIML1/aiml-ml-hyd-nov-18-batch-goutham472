{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sb7Epo0VOB58"
   },
   "source": [
    "### Load tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fHpCNRv1OB5-"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tnSsH8sNOB6F",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Reset Default graph - Needed only for Jupyter notebook\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DxJDmJqqOB6K",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FhllFLyKOB6N"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B4yQKMiJOB6R"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('prices.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fgkX6SEqOB6W"
   },
   "source": [
    "### Check all columns in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7K8pWsNQOB6X"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'symbol', 'open', 'close', 'low', 'high', 'volume'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7dU6X7MpOB6c"
   },
   "source": [
    "### Drop columns `date` and  `symbol`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lh_6spSKOB6e"
   },
   "outputs": [],
   "source": [
    "data.drop(['date','symbol'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xlwbUgTwOB6i",
    "outputId": "56bad82a-f271-415a-e0d6-cbe1c4290743"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123.430000</td>\n",
       "      <td>125.839996</td>\n",
       "      <td>122.309998</td>\n",
       "      <td>126.250000</td>\n",
       "      <td>2163600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125.239998</td>\n",
       "      <td>119.980003</td>\n",
       "      <td>119.940002</td>\n",
       "      <td>125.540001</td>\n",
       "      <td>2386400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.379997</td>\n",
       "      <td>114.949997</td>\n",
       "      <td>114.930000</td>\n",
       "      <td>119.739998</td>\n",
       "      <td>2489500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115.480003</td>\n",
       "      <td>116.620003</td>\n",
       "      <td>113.500000</td>\n",
       "      <td>117.440002</td>\n",
       "      <td>2006300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>117.010002</td>\n",
       "      <td>114.970001</td>\n",
       "      <td>114.089996</td>\n",
       "      <td>117.330002</td>\n",
       "      <td>1408600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         open       close         low        high     volume\n",
       "0  123.430000  125.839996  122.309998  126.250000  2163600.0\n",
       "1  125.239998  119.980003  119.940002  125.540001  2386400.0\n",
       "2  116.379997  114.949997  114.930000  119.739998  2489500.0\n",
       "3  115.480003  116.620003  113.500000  117.440002  2006300.0\n",
       "4  117.010002  114.970001  114.089996  117.330002  1408600.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3DBv3WWYOB6q"
   },
   "source": [
    "### Consider only first 1000 rows in the dataset for building feature set and target set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z_hG9rGBOB6s"
   },
   "outputs": [],
   "source": [
    "data1=data.iloc[:1000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set=data1.drop('close',axis=1)\n",
    "target_set=data1['close']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M3UaApqYOB6x"
   },
   "source": [
    "### Divide the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2EkKAy7fOB6y"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(feature_set,target_set,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v6vE4eYCOB62",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building the graph in tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xK0zBd1VOB64",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1.Define input data placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JDrYlWTuOB66"
   },
   "outputs": [],
   "source": [
    "#input layer\n",
    "x=tf.placeholder(shape=[None,4],dtype=tf.float32, name='x-input')\n",
    "y_=tf.placeholder(shape=[None],dtype=tf.float32,name='y-input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the data\n",
    "x_n = tf.nn.l2_normalize(x,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "297_qja4OB7A",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2.Define Weights and Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L205qPeQOB7B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.zeros(shape=[4,1]), name=\"Weights\")\n",
    "b = tf.Variable(tf.zeros(shape=[1]),name=\"Bias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HgtWA-UIOB7F",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "3.Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JveGlx25OB7H"
   },
   "outputs": [],
   "source": [
    "y=tf.add(tf.matmul(x_n,W),b,name='output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TL1hIwf_OB7M",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "4.Loss (Cost) Function [Mean square error]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8VSWPiGXOB7P"
   },
   "outputs": [],
   "source": [
    "loss=tf.reduce_mean(tf.square(y-y_),name='Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jzG85FUlOB7U",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "5.GradientDescent Optimizer to minimize Loss [GradientDescentOptimizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cj802w-3OB7X"
   },
   "outputs": [],
   "source": [
    "train_op=tf.train.GradientDescentOptimizer(0.03).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xSypb_u8OB7e",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Execute the Graph for 100 epochs and observe the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DVvgj7eQOB7f"
   },
   "outputs": [],
   "source": [
    "ses=tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9smwOW-1OB7k"
   },
   "outputs": [],
   "source": [
    "ses.run(tf.global_variables_initializer())\n",
    "training_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9JuLI6bSOB7n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at step:  0  is  3567.2136\n",
      "Training loss at step:  10  is  3567.2144\n",
      "Training loss at step:  20  is  3567.2144\n",
      "Training loss at step:  30  is  3567.2144\n",
      "Training loss at step:  40  is  3567.2144\n",
      "Training loss at step:  50  is  3567.2144\n",
      "Training loss at step:  60  is  3567.2144\n",
      "Training loss at step:  70  is  3567.2144\n",
      "Training loss at step:  80  is  3567.2144\n",
      "Training loss at step:  90  is  3567.2144\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "            \n",
    "    #Calculate train_op and loss\n",
    "    _, train_loss = ses.run([train_op,loss],feed_dict={x:x_train, y_:y_train})\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print ('Training loss at step: ', epoch, ' is ', train_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DOL2ncA1OB7q"
   },
   "source": [
    "### Get the shapes and values of W and b\n",
    "\n",
    "Hint: Use sess.run(W) to get W."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZGvtyTeuOB7r"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.6560160e-03],\n",
       "       [2.6320412e-03],\n",
       "       [2.6763959e-03],\n",
       "       [3.3293568e+01]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ses.run(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vhDtOv5UOB7x"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SZqKUEFsOB71"
   },
   "source": [
    "### Find the Absolute mean square loss difference between training and testing loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "97t-grQgOB71"
   },
   "outputs": [],
   "source": [
    "test_epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KjOInjUROB75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at step:  0  is  3018.3816\n",
      "Training loss at step:  10  is  3018.0173\n",
      "Training loss at step:  20  is  3017.9883\n",
      "Training loss at step:  30  is  3017.9846\n",
      "Training loss at step:  40  is  3017.9827\n",
      "Training loss at step:  50  is  3017.986\n",
      "Training loss at step:  60  is  3017.9834\n",
      "Training loss at step:  70  is  3017.986\n",
      "Training loss at step:  80  is  3017.9868\n",
      "Training loss at step:  90  is  3017.9868\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(test_epochs):\n",
    "            \n",
    "    #Calculate train_op and loss\n",
    "    _, test_loss = ses.run([train_op,loss],feed_dict={x:x_test, y_:y_test})\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print ('Training loss at step: ', epoch, ' is ', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CZUAjZ5oOB78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "549.22754"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff=abs(train_loss-test_loss)\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseSession.close of <tensorflow.python.client.session.Session object at 0x000001DFD60ECD68>>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ses.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YJRBuqXhOB7_"
   },
   "source": [
    "### Linear Classification using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GoNTWXAOB8C",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Building the simple Neural Network in Keras with one neuron in the dense hidden layer.\n",
    "#### Use Mean square error as loss function and sgd as optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zpeL5rCTOB8D"
   },
   "outputs": [],
   "source": [
    "#Initialize Sequential Graph (model)\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#Normalize input data\n",
    "model.add(tf.keras.layers.BatchNormalization(input_shape=(4,)))\n",
    "\n",
    "#Add Dense layer for prediction - Keras declares weights and bias automatically\n",
    "model.add(tf.keras.layers.Dense(1,activation='softmax'))\n",
    "\n",
    "#Compile the model - add Loss and Gradient Descent optimizer\n",
    "model.compile(optimizer='sgd', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wt-HYFMEOB8G",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Execute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "66JGJt7GOB8H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "700/700 [==============================] - 0s 276us/sample - loss: 7868.8898\n",
      "Epoch 2/100\n",
      "700/700 [==============================] - 0s 31us/sample - loss: 7868.8898\n",
      "Epoch 3/100\n",
      "700/700 [==============================] - 0s 40us/sample - loss: 7868.8899\n",
      "Epoch 4/100\n",
      "700/700 [==============================] - 0s 40us/sample - loss: 7868.8899\n",
      "Epoch 5/100\n",
      "700/700 [==============================] - 0s 47us/sample - loss: 7868.8898\n",
      "Epoch 6/100\n",
      "700/700 [==============================] - 0s 30us/sample - loss: 7868.8898\n",
      "Epoch 7/100\n",
      "700/700 [==============================] - 0s 49us/sample - loss: 7868.8900\n",
      "Epoch 8/100\n",
      "700/700 [==============================] - 0s 51us/sample - loss: 7868.8900\n",
      "Epoch 9/100\n",
      "700/700 [==============================] - 0s 35us/sample - loss: 7868.8899\n",
      "Epoch 10/100\n",
      "700/700 [==============================] - 0s 36us/sample - loss: 7868.8898\n",
      "Epoch 11/100\n",
      "700/700 [==============================] - 0s 40us/sample - loss: 7868.8899\n",
      "Epoch 12/100\n",
      "700/700 [==============================] - 0s 40us/sample - loss: 7868.8900\n",
      "Epoch 13/100\n",
      "700/700 [==============================] - 0s 30us/sample - loss: 7868.8899\n",
      "Epoch 14/100\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 7868.8899\n",
      "Epoch 15/100\n",
      "700/700 [==============================] - 0s 23us/sample - loss: 7868.8899\n",
      "Epoch 16/100\n",
      "700/700 [==============================] - 0s 38us/sample - loss: 7868.8898\n",
      "Epoch 17/100\n",
      "700/700 [==============================] - 0s 28us/sample - loss: 7868.8898\n",
      "Epoch 18/100\n",
      "700/700 [==============================] - 0s 23us/sample - loss: 7868.8900\n",
      "Epoch 19/100\n",
      "700/700 [==============================] - 0s 27us/sample - loss: 7868.8897\n",
      "Epoch 20/100\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 7868.8898\n",
      "Epoch 21/100\n",
      "700/700 [==============================] - 0s 42us/sample - loss: 7868.8899\n",
      "Epoch 22/100\n",
      "700/700 [==============================] - 0s 38us/sample - loss: 7868.8899\n",
      "Epoch 23/100\n",
      "700/700 [==============================] - 0s 37us/sample - loss: 7868.8897\n",
      "Epoch 24/100\n",
      "700/700 [==============================] - 0s 39us/sample - loss: 7868.8899\n",
      "Epoch 25/100\n",
      "700/700 [==============================] - 0s 30us/sample - loss: 7868.8898\n",
      "Epoch 26/100\n",
      "700/700 [==============================] - 0s 41us/sample - loss: 7868.8898\n",
      "Epoch 27/100\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 7868.8898\n",
      "Epoch 28/100\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 7868.8898\n",
      "Epoch 29/100\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 7868.8898\n",
      "Epoch 30/100\n",
      "700/700 [==============================] - 0s 37us/sample - loss: 7868.8899\n",
      "Epoch 31/100\n",
      "700/700 [==============================] - 0s 33us/sample - loss: 7868.8899\n",
      "Epoch 32/100\n",
      "700/700 [==============================] - 0s 33us/sample - loss: 7868.8899\n",
      "Epoch 33/100\n",
      "700/700 [==============================] - 0s 29us/sample - loss: 7868.8899\n",
      "Epoch 34/100\n",
      "700/700 [==============================] - 0s 29us/sample - loss: 7868.8899\n",
      "Epoch 35/100\n",
      "700/700 [==============================] - 0s 37us/sample - loss: 7868.8899\n",
      "Epoch 36/100\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 7868.8899\n",
      "Epoch 37/100\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 7868.8899\n",
      "Epoch 38/100\n",
      "700/700 [==============================] - 0s 35us/sample - loss: 7868.8899\n",
      "Epoch 39/100\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 7868.8900\n",
      "Epoch 40/100\n",
      "700/700 [==============================] - 0s 40us/sample - loss: 7868.8898\n",
      "Epoch 41/100\n",
      "700/700 [==============================] - 0s 29us/sample - loss: 7868.8898\n",
      "Epoch 42/100\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 7868.8898\n",
      "Epoch 43/100\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 7868.8898\n",
      "Epoch 44/100\n",
      "700/700 [==============================] - 0s 29us/sample - loss: 7868.8898\n",
      "Epoch 45/100\n",
      "700/700 [==============================] - 0s 51us/sample - loss: 7868.8900\n",
      "Epoch 46/100\n",
      "700/700 [==============================] - 0s 29us/sample - loss: 7868.8899\n",
      "Epoch 47/100\n",
      "700/700 [==============================] - 0s 40us/sample - loss: 7868.8898\n",
      "Epoch 48/100\n",
      "700/700 [==============================] - 0s 42us/sample - loss: 7868.8898\n",
      "Epoch 49/100\n",
      "700/700 [==============================] - 0s 29us/sample - loss: 7868.8899\n",
      "Epoch 50/100\n",
      "700/700 [==============================] - 0s 23us/sample - loss: 7868.8897\n",
      "Epoch 51/100\n",
      "700/700 [==============================] - 0s 40us/sample - loss: 7868.8897\n",
      "Epoch 52/100\n",
      "700/700 [==============================] - 0s 40us/sample - loss: 7868.8898\n",
      "Epoch 53/100\n",
      "700/700 [==============================] - 0s 29us/sample - loss: 7868.8898\n",
      "Epoch 54/100\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 7868.8898\n",
      "Epoch 55/100\n",
      "700/700 [==============================] - 0s 29us/sample - loss: 7868.8897\n",
      "Epoch 56/100\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 7868.8898\n",
      "Epoch 57/100\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 7868.8898\n",
      "Epoch 58/100\n",
      "700/700 [==============================] - 0s 40us/sample - loss: 7868.8897\n",
      "Epoch 59/100\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 7868.8898\n",
      "Epoch 60/100\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 7868.8898\n",
      "Epoch 61/100\n",
      "700/700 [==============================] - 0s 36us/sample - loss: 7868.8897\n",
      "Epoch 62/100\n",
      "700/700 [==============================] - 0s 29us/sample - loss: 7868.8899\n",
      "Epoch 63/100\n",
      "700/700 [==============================] - 0s 45us/sample - loss: 7868.8899\n",
      "Epoch 64/100\n",
      "700/700 [==============================] - 0s 36us/sample - loss: 7868.8900\n",
      "Epoch 65/100\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 7868.8898\n",
      "Epoch 66/100\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 7868.8899\n",
      "Epoch 67/100\n",
      "700/700 [==============================] - 0s 29us/sample - loss: 7868.8900\n",
      "Epoch 68/100\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 7868.8899\n",
      "Epoch 69/100\n",
      "700/700 [==============================] - 0s 29us/sample - loss: 7868.8899\n",
      "Epoch 70/100\n",
      "700/700 [==============================] - 0s 29us/sample - loss: 7868.8899\n",
      "Epoch 71/100\n",
      "700/700 [==============================] - 0s 29us/sample - loss: 7868.8898\n",
      "Epoch 72/100\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 7868.8898\n",
      "Epoch 73/100\n",
      "700/700 [==============================] - 0s 29us/sample - loss: 7868.8898\n",
      "Epoch 74/100\n",
      "700/700 [==============================] - 0s 23us/sample - loss: 7868.8897\n",
      "Epoch 75/100\n",
      "700/700 [==============================] - 0s 23us/sample - loss: 7868.8898\n",
      "Epoch 76/100\n",
      "700/700 [==============================] - 0s 29us/sample - loss: 7868.8898\n",
      "Epoch 77/100\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 7868.8897\n",
      "Epoch 78/100\n",
      "700/700 [==============================] - 0s 29us/sample - loss: 7868.8898\n",
      "Epoch 79/100\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 7868.8899\n",
      "Epoch 80/100\n",
      "700/700 [==============================] - 0s 28us/sample - loss: 7868.8899\n",
      "Epoch 81/100\n",
      "700/700 [==============================] - 0s 29us/sample - loss: 7868.8899\n",
      "Epoch 82/100\n",
      "700/700 [==============================] - 0s 29us/sample - loss: 7868.8897\n",
      "Epoch 83/100\n",
      "700/700 [==============================] - 0s 29us/sample - loss: 7868.8898\n",
      "Epoch 84/100\n",
      "700/700 [==============================] - 0s 23us/sample - loss: 7868.8899\n",
      "Epoch 85/100\n",
      "700/700 [==============================] - 0s 23us/sample - loss: 7868.8899\n",
      "Epoch 86/100\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 7868.8898\n",
      "Epoch 87/100\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 7868.8899\n",
      "Epoch 88/100\n",
      "700/700 [==============================] - 0s 29us/sample - loss: 7868.8898\n",
      "Epoch 89/100\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 7868.8898\n",
      "Epoch 90/100\n",
      "700/700 [==============================] - 0s 29us/sample - loss: 7868.8897\n",
      "Epoch 91/100\n",
      "700/700 [==============================] - 0s 29us/sample - loss: 7868.8898\n",
      "Epoch 92/100\n",
      "700/700 [==============================] - 0s 29us/sample - loss: 7868.8897\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 34us/sample - loss: 7868.8899\n",
      "Epoch 94/100\n",
      "700/700 [==============================] - 0s 29us/sample - loss: 7868.8899\n",
      "Epoch 95/100\n",
      "700/700 [==============================] - 0s 29us/sample - loss: 7868.8898\n",
      "Epoch 96/100\n",
      "700/700 [==============================] - 0s 29us/sample - loss: 7868.8899\n",
      "Epoch 97/100\n",
      "700/700 [==============================] - 0s 40us/sample - loss: 7868.8900\n",
      "Epoch 98/100\n",
      "700/700 [==============================] - 0s 33us/sample - loss: 7868.8897\n",
      "Epoch 99/100\n",
      "700/700 [==============================] - 0s 22us/sample - loss: 7868.8899\n",
      "Epoch 100/100\n",
      "700/700 [==============================] - 0s 45us/sample - loss: 7868.8898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dfd6178748>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification using Keras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the given Iris data using pandas (Iris.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt=pd.read_csv('Iris.csv')\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into feature set and target set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dt.drop(['Id','Species'],axis=1)\n",
    "Y=dt['Species']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target set has different categories. So, Label encode them. And convert into one-hot vectors using get_dummies in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_e=le.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  0\n",
       "2  0\n",
       "3  0\n",
       "4  0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target=pd.DataFrame(Y_e)\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "target1=pd.get_dummies(dt['Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iris-setosa</th>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <th>Iris-virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Iris-setosa  Iris-versicolor  Iris-virginica\n",
       "0            1                0               0\n",
       "1            1                0               0\n",
       "2            1                0               0\n",
       "3            1                0               0\n",
       "4            1                0               0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide the dataset into Training and test (70:30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(X,target1,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "Build the model with following layers: <br>\n",
    "1. First dense layer with 10 neurons with input shape 4 (according to the feature set) <br>\n",
    "2. Second Dense layer with 8 neurons <br>\n",
    "3. Output layer with 3 neurons with softmax activation (output layer, 3 neurons as we have 3 classes) <br>\n",
    "4. Use SGD and categorical_crossentropy loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#specifying activation functions\n",
    "model.add(Dense(10, input_dim=4))\n",
    "model.add(Dense(8))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the model and predicting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 0s - loss: 2.2051 - acc: 0.5714\n",
      "Epoch 2/20\n",
      " - 0s - loss: 0.6997 - acc: 0.7429\n",
      "Epoch 3/20\n",
      " - 0s - loss: 0.6440 - acc: 0.6667\n",
      "Epoch 4/20\n",
      " - 0s - loss: 0.5924 - acc: 0.7810\n",
      "Epoch 5/20\n",
      " - 0s - loss: 0.5543 - acc: 0.8000\n",
      "Epoch 6/20\n",
      " - 0s - loss: 0.5322 - acc: 0.7905\n",
      "Epoch 7/20\n",
      " - 0s - loss: 0.5273 - acc: 0.7810\n",
      "Epoch 8/20\n",
      " - 0s - loss: 0.4990 - acc: 0.8571\n",
      "Epoch 9/20\n",
      " - 0s - loss: 0.4763 - acc: 0.8667\n",
      "Epoch 10/20\n",
      " - 0s - loss: 0.4683 - acc: 0.8000\n",
      "Epoch 11/20\n",
      " - 0s - loss: 0.4442 - acc: 0.8571\n",
      "Epoch 12/20\n",
      " - 0s - loss: 0.4298 - acc: 0.8857\n",
      "Epoch 13/20\n",
      " - 0s - loss: 0.4053 - acc: 0.8381\n",
      "Epoch 14/20\n",
      " - 0s - loss: 0.4137 - acc: 0.8762\n",
      "Epoch 15/20\n",
      " - 0s - loss: 0.4093 - acc: 0.8381\n",
      "Epoch 16/20\n",
      " - 0s - loss: 0.3925 - acc: 0.8762\n",
      "Epoch 17/20\n",
      " - 0s - loss: 0.3862 - acc: 0.8667\n",
      "Epoch 18/20\n",
      " - 0s - loss: 0.3675 - acc: 0.8857\n",
      "Epoch 19/20\n",
      " - 0s - loss: 0.3611 - acc: 0.9048\n",
      "Epoch 20/20\n",
      " - 0s - loss: 0.3469 - acc: 0.9143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dfd6c17cf8>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train, nb_epoch=20, batch_size=10,  verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_p=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.5759914e-04, 4.5843083e-01, 5.4061162e-01],\n",
       "       [1.5564569e-03, 4.8079142e-01, 5.1765215e-01],\n",
       "       [1.8009242e-02, 5.5528498e-01, 4.2670578e-01],\n",
       "       [9.4928014e-01, 4.8487954e-02, 2.2318638e-03],\n",
       "       [2.3421695e-02, 5.2758497e-01, 4.4899333e-01],\n",
       "       [9.3645567e-01, 6.0785033e-02, 2.7592226e-03],\n",
       "       [9.1818273e-03, 5.7022661e-01, 4.2059159e-01],\n",
       "       [9.3297750e-01, 6.3501045e-02, 3.5214263e-03],\n",
       "       [5.4927152e-03, 5.3909940e-01, 4.5540780e-01],\n",
       "       [6.5353391e-04, 2.0663656e-01, 7.9270989e-01],\n",
       "       [9.3452775e-01, 6.2724143e-02, 2.7481613e-03],\n",
       "       [6.0619358e-03, 4.1192260e-01, 5.8201551e-01],\n",
       "       [9.6172601e-01, 3.6865525e-02, 1.4084780e-03],\n",
       "       [9.7903168e-01, 2.0029677e-02, 9.3858404e-04],\n",
       "       [3.0571662e-02, 6.0378116e-01, 3.6564720e-01],\n",
       "       [9.6505827e-01, 3.3328120e-02, 1.6135911e-03],\n",
       "       [9.0498000e-01, 8.8259526e-02, 6.7604398e-03],\n",
       "       [9.1511917e-01, 8.0001146e-02, 4.8796944e-03],\n",
       "       [9.7517055e-01, 2.4125058e-02, 7.0451992e-04],\n",
       "       [2.1665366e-04, 1.4624743e-01, 8.5353589e-01],\n",
       "       [2.1897356e-03, 4.1815579e-01, 5.7965451e-01],\n",
       "       [6.2353868e-04, 2.4990559e-01, 7.4947089e-01],\n",
       "       [6.6576933e-04, 1.6846222e-01, 8.3087194e-01],\n",
       "       [8.2270481e-02, 6.3955534e-01, 2.7817422e-01],\n",
       "       [9.5149904e-01, 4.5935888e-02, 2.5650873e-03],\n",
       "       [2.9218066e-03, 3.6332953e-01, 6.3374865e-01],\n",
       "       [3.8432881e-02, 6.3644671e-01, 3.2512048e-01],\n",
       "       [4.5010247e-03, 3.9290997e-01, 6.0258895e-01],\n",
       "       [3.0048410e-04, 4.0228891e-01, 5.9741050e-01],\n",
       "       [1.5219188e-02, 5.7714069e-01, 4.0764022e-01],\n",
       "       [2.7818608e-03, 4.8117110e-01, 5.1604700e-01],\n",
       "       [7.9904124e-04, 2.3744117e-01, 7.6175976e-01],\n",
       "       [8.8820165e-01, 1.0508796e-01, 6.7103473e-03],\n",
       "       [3.5263094e-04, 3.6577550e-01, 6.3387191e-01],\n",
       "       [2.5929233e-02, 5.8435911e-01, 3.8971162e-01],\n",
       "       [9.1322639e-05, 2.7145016e-01, 7.2845852e-01],\n",
       "       [2.3113877e-02, 5.8633006e-01, 3.9055607e-01],\n",
       "       [1.5948416e-01, 5.9953481e-01, 2.4098109e-01],\n",
       "       [3.8764339e-02, 6.8134677e-01, 2.7988887e-01],\n",
       "       [9.3452775e-01, 6.2724143e-02, 2.7481613e-03],\n",
       "       [9.4117528e-01, 5.5220038e-02, 3.6046864e-03],\n",
       "       [8.4604107e-02, 6.2681699e-01, 2.8857890e-01],\n",
       "       [1.1984054e-03, 2.6328841e-01, 7.3551321e-01],\n",
       "       [9.6073854e-01, 3.7651651e-02, 1.6097621e-03],\n",
       "       [1.6006900e-03, 3.0490640e-01, 6.9349289e-01]], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 0, 1, 0, 1, 0, 1, 2, 0, 2, 0, 0, 1, 0, 0, 0, 0, 2, 2, 2,\n",
       "       2, 1, 0, 2, 1, 2, 2, 1, 2, 2, 0, 2, 1, 2, 1, 1, 1, 0, 0, 1, 2, 0,\n",
       "       2], dtype=int64)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result=np.argmax(Y_p,axis=1)\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 0, 1, 0, 1, 0, 2, 2, 0, 2, 0, 0, 1, 0, 0, 0, 0, 2, 2, 2,\n",
       "       2, 1, 0, 2, 1, 2, 2, 1, 2, 2, 0, 2, 1, 2, 1, 1, 1, 0, 0, 1, 2, 0,\n",
       "       2], dtype=int64)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_result=np.argmax(a,axis=1)\n",
    "target_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report Accuracy of the predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy=accuracy_score(target_result,test_result)\n",
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Linear+classification+using+Tensorflow+and+Keras.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
