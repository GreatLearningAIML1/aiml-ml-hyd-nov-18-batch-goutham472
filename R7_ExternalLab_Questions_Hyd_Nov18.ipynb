{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R7_ExternalLab_Questions_Hyd_Nov18.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4WH1Pr4KQlCh"
      },
      "source": [
        "### Build a DNN using Keras with `RELU` and `ADAM`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TbvI8LqlQlCl",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "#### Load tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SPW-a-qYQlCp",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "74cQBsi5QlCw",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "#### Collect Fashion mnist data from tf.keras.datasets "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8H4gOaeJQlCx",
        "colab": {}
      },
      "source": [
        "(trainX,trainY),(testX,testY)=tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "no7aWYZyQlC1",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "#### Change train and test labels into one-hot vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UX6otc4wQlC2",
        "colab": {}
      },
      "source": [
        "trainy=tf.keras.utils.to_categorical(trainY,10)\n",
        "testy=tf.keras.utils.to_categorical(testY,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8p9nDbFfyON",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "d9404fc1-370d-46a9-ef80-50fd1b85c4b6"
      },
      "source": [
        "trainy.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMJ2yX7Tf12S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "0124dd7c-85b8-495c-f119-a059fb19bc71"
      },
      "source": [
        "testy.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QjNrRTdoQlC5",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "#### Build the Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CDJ9DHVNQlC7"
      },
      "source": [
        "#### Initialize model, reshape & normalize data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pCDQs_g1QlC8",
        "colab": {}
      },
      "source": [
        "trainX = trainX.reshape(trainX.shape[0], 28, 28, 1).astype('float32')\n",
        "testX = testX.reshape(testX.shape[0], 28, 28, 1).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ChMxPIlXhD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX /=255\n",
        "testX /=255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPkdDMwgYHH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=tf.keras.models.Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kBGwTTilQlDD",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "#### Add two fully connected layers with 200 and 100 neurons respectively with `relu` activations. Add a dropout layer with `p=0.25`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IXbfpfOzQlDF",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Flatten(input_shape=(28, 28,1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yh8D_hd0rPgI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Dense(200,activation ='relu'))\n",
        "model.add(tf.keras.layers.Dense(100,activation ='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.25))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5I8f5otcQlDJ"
      },
      "source": [
        "### Add the output layer with a fully connected layer with 10 neurons with `softmax` activation. Use `categorical_crossentropy` loss and `adam` optimizer and train the network. And, report the final validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E25kuP_NQlDM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3396
        },
        "outputId": "af76cbbc-075e-4a3c-f377-d238ebe701e0"
      },
      "source": [
        "model.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(trainX, trainy, batch_size=64, epochs=100, \n",
        "              validation_data=(testX, testy))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.5300 - acc: 0.8111 - val_loss: 0.4006 - val_acc: 0.8555\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.3827 - acc: 0.8608 - val_loss: 0.3812 - val_acc: 0.8609\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.3446 - acc: 0.8744 - val_loss: 0.3589 - val_acc: 0.8667\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.3189 - acc: 0.8821 - val_loss: 0.3470 - val_acc: 0.8742\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.3064 - acc: 0.8868 - val_loss: 0.3573 - val_acc: 0.8699\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 4s 67us/sample - loss: 0.2889 - acc: 0.8929 - val_loss: 0.3378 - val_acc: 0.8765\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 4s 70us/sample - loss: 0.2790 - acc: 0.8967 - val_loss: 0.3406 - val_acc: 0.8756\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.2677 - acc: 0.8994 - val_loss: 0.3299 - val_acc: 0.8813\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.2574 - acc: 0.9024 - val_loss: 0.3297 - val_acc: 0.8814\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.2510 - acc: 0.9058 - val_loss: 0.3295 - val_acc: 0.8840\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.2412 - acc: 0.9084 - val_loss: 0.3395 - val_acc: 0.8826\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.2328 - acc: 0.9114 - val_loss: 0.3279 - val_acc: 0.8843\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.2272 - acc: 0.9133 - val_loss: 0.3442 - val_acc: 0.8841\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.2216 - acc: 0.9156 - val_loss: 0.3521 - val_acc: 0.8865\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.2166 - acc: 0.9181 - val_loss: 0.3578 - val_acc: 0.8866\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.2087 - acc: 0.9196 - val_loss: 0.3443 - val_acc: 0.8873\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.2026 - acc: 0.9222 - val_loss: 0.3340 - val_acc: 0.8907\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.1998 - acc: 0.9242 - val_loss: 0.3354 - val_acc: 0.8911\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 4s 67us/sample - loss: 0.1968 - acc: 0.9256 - val_loss: 0.3433 - val_acc: 0.8905\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.1897 - acc: 0.9279 - val_loss: 0.3494 - val_acc: 0.8896\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.1852 - acc: 0.9291 - val_loss: 0.3438 - val_acc: 0.8925\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.1811 - acc: 0.9300 - val_loss: 0.3631 - val_acc: 0.8870\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.1770 - acc: 0.9319 - val_loss: 0.3480 - val_acc: 0.8900\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.1724 - acc: 0.9340 - val_loss: 0.3570 - val_acc: 0.8863\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.1683 - acc: 0.9347 - val_loss: 0.3521 - val_acc: 0.8921\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.1664 - acc: 0.9358 - val_loss: 0.3484 - val_acc: 0.8945\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.1641 - acc: 0.9364 - val_loss: 0.3650 - val_acc: 0.8947\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.1620 - acc: 0.9378 - val_loss: 0.3832 - val_acc: 0.8881\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.1569 - acc: 0.9396 - val_loss: 0.3918 - val_acc: 0.8951\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.1550 - acc: 0.9407 - val_loss: 0.3836 - val_acc: 0.8897\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.1514 - acc: 0.9417 - val_loss: 0.4156 - val_acc: 0.8888\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.1461 - acc: 0.9437 - val_loss: 0.3886 - val_acc: 0.8923\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.1467 - acc: 0.9441 - val_loss: 0.4019 - val_acc: 0.8925\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.1440 - acc: 0.9445 - val_loss: 0.4132 - val_acc: 0.8933\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.1382 - acc: 0.9461 - val_loss: 0.4000 - val_acc: 0.8897\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.1419 - acc: 0.9453 - val_loss: 0.4500 - val_acc: 0.8868\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.1335 - acc: 0.9490 - val_loss: 0.4035 - val_acc: 0.8941\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.1333 - acc: 0.9476 - val_loss: 0.4474 - val_acc: 0.8919\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.1313 - acc: 0.9490 - val_loss: 0.4589 - val_acc: 0.8889\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.1297 - acc: 0.9500 - val_loss: 0.4308 - val_acc: 0.8936\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.1274 - acc: 0.9506 - val_loss: 0.4633 - val_acc: 0.8916\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.1251 - acc: 0.9513 - val_loss: 0.4626 - val_acc: 0.8902\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.1262 - acc: 0.9506 - val_loss: 0.4667 - val_acc: 0.8908\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.1225 - acc: 0.9527 - val_loss: 0.4690 - val_acc: 0.8908\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.1192 - acc: 0.9534 - val_loss: 0.4911 - val_acc: 0.8867\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 4s 67us/sample - loss: 0.1184 - acc: 0.9521 - val_loss: 0.4751 - val_acc: 0.8910\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 4s 68us/sample - loss: 0.1194 - acc: 0.9543 - val_loss: 0.4701 - val_acc: 0.8932\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 4s 69us/sample - loss: 0.1158 - acc: 0.9549 - val_loss: 0.4991 - val_acc: 0.8926\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.1106 - acc: 0.9567 - val_loss: 0.5185 - val_acc: 0.8975\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.1113 - acc: 0.9559 - val_loss: 0.5106 - val_acc: 0.8848\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.1114 - acc: 0.9564 - val_loss: 0.4706 - val_acc: 0.8933\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.1103 - acc: 0.9567 - val_loss: 0.4903 - val_acc: 0.8959\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.1072 - acc: 0.9575 - val_loss: 0.5477 - val_acc: 0.8942\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.1083 - acc: 0.9577 - val_loss: 0.5092 - val_acc: 0.8953\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.1034 - acc: 0.9600 - val_loss: 0.5317 - val_acc: 0.8945\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.1031 - acc: 0.9593 - val_loss: 0.5344 - val_acc: 0.8929\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.1046 - acc: 0.9583 - val_loss: 0.5402 - val_acc: 0.8936\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0986 - acc: 0.9614 - val_loss: 0.5296 - val_acc: 0.8923\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.1008 - acc: 0.9607 - val_loss: 0.5687 - val_acc: 0.8923\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0981 - acc: 0.9616 - val_loss: 0.5385 - val_acc: 0.8923\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.0993 - acc: 0.9617 - val_loss: 0.5177 - val_acc: 0.8909\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0958 - acc: 0.9624 - val_loss: 0.5528 - val_acc: 0.8909\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.0937 - acc: 0.9635 - val_loss: 0.5721 - val_acc: 0.8956\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0950 - acc: 0.9630 - val_loss: 0.5650 - val_acc: 0.8931\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.0957 - acc: 0.9626 - val_loss: 0.5615 - val_acc: 0.8960\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.0911 - acc: 0.9642 - val_loss: 0.5910 - val_acc: 0.8952\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0923 - acc: 0.9640 - val_loss: 0.6231 - val_acc: 0.8960\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0927 - acc: 0.9631 - val_loss: 0.5830 - val_acc: 0.8927\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.0909 - acc: 0.9644 - val_loss: 0.5819 - val_acc: 0.8917\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0895 - acc: 0.9651 - val_loss: 0.5903 - val_acc: 0.8937\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.0864 - acc: 0.9654 - val_loss: 0.6051 - val_acc: 0.8955\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0881 - acc: 0.9655 - val_loss: 0.6678 - val_acc: 0.8930\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0864 - acc: 0.9668 - val_loss: 0.6499 - val_acc: 0.8935\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.0874 - acc: 0.9665 - val_loss: 0.6422 - val_acc: 0.8952\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0826 - acc: 0.9681 - val_loss: 0.6401 - val_acc: 0.8911\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.0806 - acc: 0.9683 - val_loss: 0.6743 - val_acc: 0.8939\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0868 - acc: 0.9663 - val_loss: 0.6539 - val_acc: 0.8959\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0832 - acc: 0.9678 - val_loss: 0.6356 - val_acc: 0.8929\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.0803 - acc: 0.9682 - val_loss: 0.6635 - val_acc: 0.8910\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0816 - acc: 0.9687 - val_loss: 0.7119 - val_acc: 0.8961\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0806 - acc: 0.9688 - val_loss: 0.6870 - val_acc: 0.8956\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.0803 - acc: 0.9678 - val_loss: 0.7004 - val_acc: 0.8943\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0788 - acc: 0.9693 - val_loss: 0.6680 - val_acc: 0.8948\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 4s 70us/sample - loss: 0.0801 - acc: 0.9688 - val_loss: 0.6503 - val_acc: 0.8960\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 4s 67us/sample - loss: 0.0773 - acc: 0.9696 - val_loss: 0.6566 - val_acc: 0.8916\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0761 - acc: 0.9701 - val_loss: 0.7103 - val_acc: 0.8932\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.0738 - acc: 0.9707 - val_loss: 0.6887 - val_acc: 0.8948\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0756 - acc: 0.9712 - val_loss: 0.6672 - val_acc: 0.8921\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.0703 - acc: 0.9720 - val_loss: 0.7382 - val_acc: 0.8942\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.0725 - acc: 0.9722 - val_loss: 0.7365 - val_acc: 0.8948\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0751 - acc: 0.9714 - val_loss: 0.7239 - val_acc: 0.8962\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0713 - acc: 0.9719 - val_loss: 0.7289 - val_acc: 0.8964\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0727 - acc: 0.9718 - val_loss: 0.7360 - val_acc: 0.8957\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0763 - acc: 0.9704 - val_loss: 0.7152 - val_acc: 0.8905\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0687 - acc: 0.9731 - val_loss: 0.7487 - val_acc: 0.8945\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0713 - acc: 0.9725 - val_loss: 0.7539 - val_acc: 0.8948\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0702 - acc: 0.9729 - val_loss: 0.7693 - val_acc: 0.8903\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0718 - acc: 0.9727 - val_loss: 0.7524 - val_acc: 0.8935\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0687 - acc: 0.9733 - val_loss: 0.7712 - val_acc: 0.8948\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.0661 - acc: 0.9753 - val_loss: 0.7549 - val_acc: 0.8949\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f26f0cc2080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8KXqmUDW2rM1"
      },
      "source": [
        "## **DATA AUGMENTATION ON CIFAR10 DATASET**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8mja6OgQ3L18"
      },
      "source": [
        "One of the best ways to improve the performance of a Deep Learning model is to add more data to the training set. Aside from gathering more instances from the wild that are representative of the distinction task, we want to develop a set of methods that enhance the data we already have. There are many ways to augment existing datasets and produce more robust models. In the image domain, these are done to utilize the full power of the convolutional neural network, which is able to capture translational invariance. This translational invariance is what makes image recognition such a difficult task in the first place. You want the dataset to be representative of the many different positions, angles, lightings, and miscellaneous distortions that are of interest to the vision task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6HzVTPUM3WZJ"
      },
      "source": [
        "### **Import neessary libraries for data augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PPM558TX4KMb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "c5af3289-7cf9-42f0-ff32-77cda602cad0"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W6hicLwP4SqY"
      },
      "source": [
        "### **Load CIFAR10 dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NQ1WzrXd4WNk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "19ea19cc-f9fc-49d5-c0fd-ea9791c8ae5c"
      },
      "source": [
        "(trainX,trainY),(testX,testY)=tf.keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R9Pht1ggHuiT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "ccc02088-8f32-4a82-e931-c1ed8eeffec9"
      },
      "source": [
        "trainX.shape"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3n28ccU6Hp6s",
        "colab": {}
      },
      "source": [
        "trainX = trainX.reshape(trainX.shape[0], 32, 32, 3).astype('float32')\n",
        "testX = testX.reshape(testX.shape[0], 32, 32, 3).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaNtf3_T2Qp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX /= 255\n",
        "testX /=255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JN3vYYhK4W0u"
      },
      "source": [
        "### **Create a data_gen funtion to genererator with image rotation,shifting image horizontally and vertically with random flip horizontally.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JJbekTKi4cmM",
        "colab": {}
      },
      "source": [
        "# This will do preprocessing and realtime data augmentation:\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    rotation_range=90,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=True,  # randomly flip images\n",
        "    vertical_flip=True)  # randomly flip images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e-SLtUhC4dK2"
      },
      "source": [
        "### **Prepare/fit the generator.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CSw8Bv2_4hb0",
        "colab": {}
      },
      "source": [
        "datagen.fit(trainX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gYyF-P8O4jQ8"
      },
      "source": [
        "### **Generate 5 images for 1 of the image of CIFAR10 train dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mXug4z234mwQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "d5207e01-2758-4ca6-990d-21cb47961217"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "gen = datagen.flow(trainX[0:1], batch_size=1)\n",
        "for i in range(1, 6):\n",
        "    plt.subplot(1,5,i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
        "    plt.plot()\n",
        "plt.show()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAABcCAYAAAB3AO7GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY9r95Up0sh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDkhO0emdmzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKxLWQcKdmzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXWxiXkndmzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TYTErd_dmzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fifCZqPBdmzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qGWiXPxdmzi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su_gyeZidmzk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}